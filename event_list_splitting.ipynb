{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('events').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "conf = SparkConf().setAppName(\"events\").setMaster(\"local\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlc = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readdataframe = spark.read.option(\"sep\",\"\\t\").csv(\"examples.tsv\",header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an identifier column for traversing the rows\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import row_number\n",
    "w = Window.orderBy(\"userid\")\n",
    "result = readdataframe.withColumn(\"index\", row_number().over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting all the unique rows of the dataset\n",
    "uniqueindexes = [list(x.asDict().values())[0] for x in result.select(\"index\").collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the distinct events from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the distinct events from the dataset\n",
    "distinctevents = [list(x.asDict().values())[0] for x in result.select(\"event\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the events from all the rows and finding the unique out of all the extracted events\n",
    "used1=[]\n",
    "for j in range(0,len(distinctevents)):\n",
    "    s=distinctevents[j].split(\",\")\n",
    "    for i in range(0,len(s)):\n",
    "        unique = [x for x in s if x not in used1 and used1.append(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the extracted events\n",
    "sort=sorted(used1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the distinct events from each row of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a spark dataframe\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "schema = StructType([\n",
    "    StructField(\"rowid\",IntegerType(),True)\n",
    "    \n",
    "])\n",
    "event2 = spark.createDataFrame(sc.emptyRDD(), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the unique events as columns\n",
    "from pyspark.sql.functions import lit \n",
    "outcols = []\n",
    "for column in sort:\n",
    "    if column in event2.columns:\n",
    "        outcols.append(column)\n",
    "    else:\n",
    "        outcols.append(lit(None).cast(StringType()).alias('{0}'.format(column)))\n",
    "\n",
    "event2 = event2.select(outcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the column names in a variable\n",
    "c=event2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the unique events for a particular row using list and storing it as a tuple\n",
    "event1=[]\n",
    "unique=[]\n",
    "list1=[]\n",
    "label2=[]\n",
    "for x in uniqueindexes:\n",
    "    for x in result.where(result.index == x).select(\"event\").collect():\n",
    "        event1=list(x.asDict().values())\n",
    "        s=str(event1)[2:-2]#removing the brackets assigned because of list and converting to a string\n",
    "        t=s.split(\",\")\n",
    "        for i in range(0,len(t)):\n",
    "            used=[]\n",
    "            unique = [i for i in t if i not in used and used.append(i)]\n",
    "            u=sorted(used)\n",
    "            label=[]\n",
    "            for i in range(0,len(sort)):\n",
    "                if sort[i] in u:\n",
    "                    label.append(1)\n",
    "                else:\n",
    "                    label.append(0)\n",
    "        tuple1=tuple(label)\n",
    "        label2.append(tuple1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe from the obtained list of unique events where 1 means the event is present and 0 indicates absent\n",
    "import pandas as pd\n",
    "newdf=pd.DataFrame(data=label2, columns=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.join(newdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
